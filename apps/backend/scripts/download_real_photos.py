#!/usr/bin/env python3
"""
AI Human Detector - GerÃ§ek Ä°nsan FotoÄŸraflarÄ± Ä°ndirme Scripti

Unsplash API'den gerÃ§ek insan fotoÄŸraflarÄ± indirir.
KullanÄ±m:
    python scripts/download_real_photos.py --num-samples 1000 --output ./data/datasets
"""

import os
import sys
import argparse
import requests
from pathlib import Path
from typing import Optional
import logging
import time

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies() -> bool:
    """Gerekli kÃ¼tÃ¼phaneleri kontrol eder."""
    try:
        from PIL import Image
        from io import BytesIO
        logger.info("âœ… TÃ¼m baÄŸÄ±mlÄ±lÄ±klar kurulu")
        return True
    except ImportError as e:
        logger.error(f"âŒ Eksik baÄŸÄ±mlÄ±lÄ±k: {e}")
        logger.info("Kurulum iÃ§in: pip install pillow requests")
        return False


def download_pexels_people(
    output_dir: Path,
    api_key: str,
    num_samples: Optional[int] = None,
    per_page: int = 80
) -> Path:
    """
    Pexels'ten gerÃ§ek insan fotoÄŸraflarÄ± indirir.

    Args:
        output_dir: Ã‡Ä±ktÄ± dizini
        api_key: Pexels API key
        num_samples: Ä°ndirilecek Ã¶rnek sayÄ±sÄ± (varsayÄ±lan: 1000)
        per_page: Her sayfadaki gÃ¶rsel sayÄ±sÄ± (max 80)

    Returns:
        Ä°ndirilen verisetinin dizini
    """
    try:
        from PIL import Image
        from io import BytesIO

        if num_samples is None:
            num_samples = 1000

        logger.info(f"ğŸ“¥ Pexels'ten {num_samples} gerÃ§ek insan fotoÄŸrafÄ± indiriliyor...")

        # Ã‡Ä±ktÄ± dizinini oluÅŸtur
        real_dir = output_dir / "real" / "pexels_people"
        real_dir.mkdir(parents=True, exist_ok=True)

        # Pexels API endpoint
        base_url = "https://api.pexels.com/v1/search"

        # Ä°nsan odaklÄ± arama terimleri
        search_queries = [
            "person",
            "people",
            "human",
            "portrait",
            "man",
            "woman",
            "children",
            "friends",
            "family",
            "couple"
        ]

        count = 0
        page = 1

        # Her query iÃ§in dÃ¶ngÃ¼
        for query_idx, query in enumerate(search_queries):
            if count >= num_samples:
                break

            logger.info(f"  Arama terimi: '{query}' ({query_idx + 1}/{len(search_queries)})")

            while count < num_samples:
                try:
                    # API isteÄŸi
                    params = {
                        "query": query,
                        "per_page": per_page,
                        "page": page,
                        "orientation": "all"  # landscape, portrait, square
                    }

                    headers = {
                        "Authorization": api_key
                    }

                    response = requests.get(
                        base_url,
                        params=params,
                        headers=headers,
                        timeout=30
                    )

                    if response.status_code != 200:
                        logger.warning(f"âš ï¸ API hatasÄ±: {response.status_code}")
                        break

                    data = response.json()

                    if not data.get("photos"):
                        logger.info(f"  '{query}' iÃ§in daha fazla sonuÃ§ yok")
                        break

                    # GÃ¶rselleri indir
                    for photo in data["photos"]:
                        if count >= num_samples:
                            break

                        try:
                            # GÃ¶rsel URL'sini al (original veya large)
                            image_url = photo["src"]["large"]  # 1920px geniÅŸlik

                            # GÃ¶rseli indir
                            img_response = requests.get(image_url, timeout=30)
                            if img_response.status_code != 200:
                                continue

                            # PIL Image olarak aÃ§
                            img = Image.open(BytesIO(img_response.content))

                            # RGB'ye Ã§evir (gerekirse)
                            if img.mode != 'RGB':
                                img = img.convert('RGB')

                            # Kaydet
                            image_path = real_dir / f"pexels_{count:06d}.jpg"
                            img.save(image_path, quality=95)
                            count += 1

                            # Ä°lerleme
                            if count % 50 == 0:
                                logger.info(f"  Ä°ndirilen: {count}/{num_samples}")

                        except Exception as e:
                            logger.warning(f"âš ï¸ GÃ¶rsel indirilemedi: {e}")
                            continue

                    page += 1

                    # Rate limiting - Pexels: 200 requests/hour
                    time.sleep(1)  # 1 saniye bekle

                    # EÄŸer bu query iÃ§in sonuÃ§lar bittiyse
                    if len(data["photos"]) < per_page:
                        logger.info(f"  '{query}' iÃ§in tÃ¼m sonuÃ§lar indirildi")
                        break

                except Exception as e:
                    logger.error(f"âŒ Ä°ndirme hatasÄ±: {e}")
                    time.sleep(5)
                    continue

            # Sonraki query iÃ§in page'i sÄ±fÄ±rla
            page = 1

            # Rate limiting iÃ§in bekle
            time.sleep(1)

        logger.info(f"âœ… {count} gerÃ§ek insan fotoÄŸrafÄ± indirildi -> {real_dir}")
        return real_dir

    except Exception as e:
        logger.error(f"âŒ Unsplash indirme hatasÄ±: {e}")
        raise


def main():
    parser = argparse.ArgumentParser(
        description="AI Human Detector - GerÃ§ek Ä°nsan FotoÄŸraflarÄ± Ä°ndirme Scripti"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="./data/datasets",
        help="Ã‡Ä±ktÄ± dizini"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        required=True,
        help="Pexels API Key"
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=1000,
        help="Ä°ndirilecek Ã¶rnek sayÄ±sÄ± (varsayÄ±lan: 1000)"
    )

    args = parser.parse_args()

    # BaÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
    if not check_dependencies():
        sys.exit(1)

    try:
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)

        # Pexels'ten gerÃ§ek insan fotoÄŸraflarÄ± indir
        download_pexels_people(
            output_dir=output_dir,
            api_key=args.api_key,
            num_samples=args.num_samples
        )

        logger.info("ğŸ‰ Ä°ndirme tamamlandÄ±!")

        # Ã–zet bilgi
        real_dir = output_dir / "real" / "pexels_people"
        if real_dir.exists():
            num_images = len(list(real_dir.glob("*.jpg")))
            logger.info(f"ğŸ“Š Toplam {num_images} gerÃ§ek insan fotoÄŸrafÄ± indirildi")

    except Exception as e:
        logger.error(f"âŒ Hata: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
