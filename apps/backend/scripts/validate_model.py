#!/usr/bin/env python3
"""
AI Human Detector - Model DoÄŸrulama Script'i

Bu script, eÄŸitilmiÅŸ modeli test seti Ã¼zerinde deÄŸerlendirir ve:
- Accuracy, Precision, Recall, F1 hesaplar
- ROC curve oluÅŸturur
- Confusion matrix oluÅŸturur
- False positive analizi yapar

KullanÄ±m:
    python scripts/validate_model.py --data ./data/processed/test --output ./results
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import List, Tuple, Dict
import logging
import time

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies() -> bool:
    """
    Gerekli kÃ¼tÃ¼phanelerin kurulu olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    """
    try:
        import PIL
        import numpy as np
        import matplotlib
        logger.info("âœ… TÃ¼m baÄŸÄ±mlÄ±lÄ±klar kurulu")
        return True
    except ImportError as e:
        logger.error(f"âŒ Eksik baÄŸÄ±mlÄ±lÄ±k: {e}")
        logger.info("Kurulum iÃ§in: pip install pillow numpy matplotlib scikit-learn")
        return False


def load_images_from_directory(directory: Path, max_images: int = None) -> List[Tuple[Path, int]]:
    """
    Dizinden gÃ¶rselleri yÃ¼kler.

    Args:
        directory: GÃ¶rsel dizini
        max_images: Maksimum gÃ¶rsel sayÄ±sÄ± (None = tÃ¼mÃ¼)

    Returns:
        (dosya_yolu, etiket) listesi
        Etiket: 0 = REAL, 1 = FAKE
    """
    from PIL import Image

    image_files = []
    for ext in ["*.png", "*.jpg", "*.jpeg", "*.webp"]:
        image_files.extend(directory.glob(ext))

    if max_images:
        image_files = image_files[:max_images]

    return [(f, 0) for f in image_files]  # 0 = REAL (default, will be overridden)


def load_test_dataset(test_dir: Path, max_per_class: int = None) -> Tuple[List[Tuple[str, 'np.ndarray', int]], Dict]:
    """
    Test veri setini yÃ¼kler.

    Args:
        test_dir: Test dizini (real/fake klasÃ¶rleri)
        max_per_class: Her sÄ±nÄ±f iÃ§in maksimum gÃ¶rsel sayÄ±sÄ±

    Returns:
        (dosya_adÄ±, gÃ¶rsel, etiket) listesi ve bilgi sÃ¶zlÃ¼ÄŸÃ¼
    """
    from PIL import Image
    import numpy as np

    logger.info("ğŸ“Š Test veri seti yÃ¼kleniyor...")

    dataset = []
    info = {"real": 0, "fake": 0}

    # Real gÃ¶rseller
    real_dir = test_dir / "real"
    if real_dir.exists():
        for img_path in real_dir.glob("*.png"):
            if max_per_class and info["real"] >= max_per_class:
                break
            try:
                img = Image.open(img_path)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img_array = np.array(img)
                dataset.append((img_path.name, img_array, 0))  # 0 = REAL
                info["real"] += 1
            except Exception as e:
                logger.warning(f"âš ï¸ GÃ¶rsel atlandÄ± {img_path.name}: {e}")

    # Fake gÃ¶rseller
    fake_dir = test_dir / "fake"
    if fake_dir.exists():
        for img_path in fake_dir.glob("*.png"):
            if max_per_class and info["fake"] >= max_per_class:
                break
            try:
                img = Image.open(img_path)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                img_array = np.array(img)
                dataset.append((img_path.name, img_array, 1))  # 1 = FAKE
                info["fake"] += 1
            except Exception as e:
                logger.warning(f"âš ï¸ GÃ¶rsel atlandÄ± {img_path.name}: {e}")

    logger.info(f"âœ… Veri seti yÃ¼klendi: {info['real']} REAL, {info['fake']} FAKE")
    return dataset, info


def initialize_ensemble():
    """
    Ensemble motorunu baÅŸlatÄ±r.

    Returns:
        EnsembleEngine
    """
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))

    from core.ensemble import EnsembleEngine
    from nodes.watermark import WatermarkNode
    from nodes.frequency import FrequencyNode

    try:
        from nodes.clip import CLIPNode
        has_clip = True
    except ImportError:
        logger.warning("âš ï¸ CLIP node kurulmamÄ±ÅŸ, atlanÄ±yor")
        has_clip = False

    try:
        from nodes.dire import DIRENode
        has_dire = True
    except ImportError:
        logger.warning("âš ï¸ DIRE node kurulmamÄ±ÅŸ, atlanÄ±yor")
        has_dire = False

    nodes = [
        WatermarkNode(weight=1.0),
        FrequencyNode(weight=1.0),
    ]

    if has_clip:
        nodes.append(CLIPNode(weight=1.0))

    if has_dire:
        nodes.append(DIRENode(weight=1.5))

    engine = EnsembleEngine(nodes=nodes, threshold=50.0)
    logger.info(f"âœ… Ensemble motoru baÅŸlatÄ±ldÄ±: {len(nodes)} node")

    return engine


def compute_metrics(
    y_true: List[int],
    y_pred: List[int],
    y_scores: List[float]
) -> Dict[str, float]:
    """
    SÄ±nÄ±flandÄ±rma metriklerini hesaplar.

    Args:
        y_true: GerÃ§ek etiketler (0=REAL, 1=FAKE)
        y_pred: Tahmin edilen etiketler
        y_scores: Tahmin skorlarÄ± (0-100)

    Returns:
        Metrik sÃ¶zlÃ¼ÄŸÃ¼
    """
    import numpy as np
    from sklearn.metrics import (
        accuracy_score,
        precision_score,
        recall_score,
        f1_score,
        confusion_matrix,
        roc_curve,
        auc
    )

    metrics = {}

    # Basic metrics
    metrics['accuracy'] = accuracy_score(y_true, y_pred)
    metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)
    metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)
    metrics['f1_score'] = f1_score(y_true, y_pred, zero_division=0)

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    metrics['confusion_matrix'] = cm.tolist()

    # TN, FP, FN, TP
    tn, fp, fn, tp = cm.ravel()
    metrics['true_negative'] = int(tn)
    metrics['false_positive'] = int(fp)
    metrics['false_negative'] = int(fn)
    metrics['true_positive'] = int(tp)

    # False Positive Rate
    metrics['false_positive_rate'] = fp / (fp + tn) if (fp + tn) > 0 else 0.0

    # ROC AUC
    fpr, tpr, thresholds = roc_curve(y_true, [s / 100.0 for s in y_scores])
    metrics['roc_auc'] = auc(fpr, tpr)
    metrics['roc_curve'] = {
        'fpr': fpr.tolist(),
        'tpr': tpr.tolist(),
        'thresholds': thresholds.tolist()
    }

    return metrics


def plot_confusion_matrix(cm, output_path: Path):
    """
    Confusion matrix gÃ¶rselleÅŸtirir.

    Args:
        cm: Confusion matrix
        output_path: Ã‡Ä±ktÄ± dosyasÄ±
    """
    import matplotlib.pyplot as plt
    import seaborn as sns

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['REAL', 'FAKE'],
                yticklabels=['REAL', 'FAKE'])
    plt.title('Confusion Matrix')
    plt.ylabel('GerÃ§ek Etiket')
    plt.xlabel('Tahmin Edilen Etiket')
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()
    logger.info(f"âœ… Confusion matrix kaydedildi: {output_path}")


def plot_roc_curve(fpr, tpr, roc_auc, output_path: Path):
    """
    ROC curve gÃ¶rselleÅŸtirir.

    Args:
        fpr: False positive rate
        tpr: True positive rate
        roc_auc: AUC skoru
        output_path: Ã‡Ä±ktÄ± dosyasÄ±
    """
    import matplotlib.pyplot as plt

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - AI Detection')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()
    logger.info(f"âœ… ROC curve kaydedildi: {output_path}")


def plot_score_distribution(y_scores_real, y_scores_fake, output_path: Path):
    """
    Skor daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtirir.

    Args:
        y_scores_real: Real gÃ¶rsellerin skorlarÄ±
        y_scores_fake: Fake gÃ¶rsellerin skorlarÄ±
        output_path: Ã‡Ä±ktÄ± dosyasÄ±
    """
    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 6))
    plt.hist(y_scores_real, bins=30, alpha=0.5, label='REAL', color='green')
    plt.hist(y_scores_fake, bins=30, alpha=0.5, label='FAKE', color='red')
    plt.axvline(x=50, color='black', linestyle='--', label='Threshold (50)')
    plt.xlabel('AI OlasÄ±lÄ±k Skoru (0-100)')
    plt.ylabel('GÃ¶rsel SayÄ±sÄ±')
    plt.title('Skor DaÄŸÄ±lÄ±mÄ±')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()
    logger.info(f"âœ… Skor daÄŸÄ±lÄ±mÄ± kaydedildi: {output_path}")


def analyze_false_positives(dataset, y_true, y_pred, y_scores, output_dir: Path):
    """
    False positive Ã¶rneklerini analiz eder.

    Args:
        dataset: (dosya_adÄ±, gÃ¶rsel, etiket) listesi
        y_true: GerÃ§ek etiketler
        y_pred: Tahmin edilen etiketler
        y_scores: Tahmin skorlarÄ±
        output_dir: Ã‡Ä±ktÄ± dizini
    """
    import numpy as np

    false_positives = []
    false_negatives = []

    for i, (filename, _, true_label) in enumerate(dataset):
        pred_label = y_pred[i]
        score = y_scores[i]

        if true_label == 0 and pred_label == 1:
            # Real -> Fake tahmini (False Positive)
            false_positives.append((filename, score))
        elif true_label == 1 and pred_label == 0:
            # Fake -> Real tahmini (False Negative)
            false_negatives.append((filename, score))

    # Rapor oluÅŸtur
    report_path = output_dir / "false_positive_analysis.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# False Positive Analizi\n\n")

        f.write("## Ã–zet\n\n")
        f.write(f"- **False Positive (Real â†’ Fake)**: {len(false_positives)} gÃ¶rsel\n")
        f.write(f"- **False Negative (Fake â†’ Real)**: {len(false_negatives)} gÃ¶rsel\n\n")

        if false_positives:
            f.write("## False Positive Ã–rnekleri (Real â†’ Fake)\n\n")
            f.write("| Dosya AdÄ± | Skor |\n")
            f.write("|----------|------|\n")
            for filename, score in sorted(false_positives, key=lambda x: x[1], reverse=True)[:20]:
                f.write(f"| {filename} | {score:.2f} |\n")
            f.write("\n")

        if false_negatives:
            f.write("## False Negative Ã–rnekleri (Fake â†’ Real)\n\n")
            f.write("| Dosya AdÄ± | Skor |\n")
            f.write("|----------|------|\n")
            for filename, score in sorted(false_negatives, key=lambda x: x[1])[:20]:
                f.write(f"| {filename} | {score:.2f} |\n")
            f.write("\n")

    logger.info(f"âœ… False positive analizi kaydedildi: {report_path}")


def generate_report(metrics: Dict, output_dir: Path):
    """
    DetaylÄ± doÄŸrulama raporu oluÅŸturur.

    Args:
        metrics: Metrik sÃ¶zlÃ¼ÄŸÃ¼
        output_dir: Ã‡Ä±ktÄ± dizini
    """
    report_path = output_dir / "validation_report.md"

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# AI Human Detector - Model DoÄŸrulama Raporu\n\n")

        f.write("## ğŸ“Š SÄ±nÄ±flandÄ±rma Metrikleri\n\n")
        f.write("| Metrik | DeÄŸer |\n")
        f.write("|--------|-------|\n")
        f.write(f"| **Accuracy** | {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%) |\n")
        f.write(f"| **Precision** | {metrics['precision']:.4f} |\n")
        f.write(f"| **Recall** | {metrics['recall']:.4f} |\n")
        f.write(f"| **F1 Score** | {metrics['f1_score']:.4f} |\n")
        f.write(f"| **ROC AUC** | {metrics['roc_auc']:.4f} |\n")
        f.write(f"| **False Positive Rate** | {metrics['false_positive_rate']:.4f} ({metrics['false_positive_rate']*100:.2f}%) |\n\n")

        f.write("## ğŸ¯ Confusion Matrix\n\n")
        cm = metrics['confusion_matrix']
        f.write("| | Tahmin: REAL | Tahmin: FAKE |\n")
        f.write("|----------|-------------|--------------|\n")
        f.write(f"| **GerÃ§ek: REAL** | {cm[0][0]} (TN) | {cm[0][1]} (FP) |\n")
        f.write(f"| **GerÃ§ek: FAKE** | {cm[1][0]} (FN) | {cm[1][1]} (TP) |\n\n")

        f.write("### Detaylar\n\n")
        f.write(f"- **True Negative (TN)**: {metrics['true_negative']} - Real doÄŸru tanÄ±mlandÄ±\n")
        f.write(f"- **False Positive (FP)**: {metrics['false_positive']} - Real yanlÄ±ÅŸ fake olarak tanÄ±mlandÄ±\n")
        f.write(f"- **False Negative (FN)**: {metrics['false_negative']} - Fake yanlÄ±ÅŸ real olarak tanÄ±mlandÄ±\n")
        f.write(f"- **True Positive (TP)**: {metrics['true_positive']} - Fake doÄŸru tanÄ±mlandÄ±\n\n")

        f.write("## ğŸ“ˆ GÃ¶rseller\n\n")
        f.write("AÅŸaÄŸÄ±daki gÃ¶rseller `results/` dizininde kaydedilmiÅŸtir:\n\n")
        f.write("- `confusion_matrix.png` - Confusion matrix gÃ¶rselleÅŸtirmesi\n")
        f.write("- `roc_curve.png` - ROC curve\n")
        f.write("- `score_distribution.png` - Skor daÄŸÄ±lÄ±mÄ±\n\n")

        f.write("## ğŸ¯ Hedefler vs GerÃ§ekÃ§ek\n\n")
        f.write("| Metrik | Hedef | GerÃ§ekÃ§ek | Durum |\n")
        f.write("|--------|-------|-----------|-------|\n")
        accuracy_status = "âœ…" if metrics['accuracy'] >= 0.95 else "âš ï¸"
        f.write(f"| Accuracy | %95+ | %{metrics['accuracy']*100:.2f} | {accuracy_status} |\n")
        fpr_status = "âœ…" if metrics['false_positive_rate'] <= 0.02 else "âš ï¸"
        f.write(f"| FPR | <%2 | %{metrics['false_positive_rate']*100:.2f} | {fpr_status} |\n\n")

    logger.info(f"âœ… DoÄŸrulama raporu kaydedildi: {report_path}")


def save_metrics_json(metrics: Dict, output_path: Path):
    """
    Metrikleri JSON formatÄ±nda kaydeder.

    Args:
        metrics: Metrik sÃ¶zlÃ¼ÄŸÃ¼
        output_path: Ã‡Ä±ktÄ± dosyasÄ±
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2)
    logger.info(f"âœ… Metrikler kaydedildi: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="AI Human Detector - Model DoÄŸrulama Script'i"
    )
    parser.add_argument(
        "--data",
        type=str,
        default="./data/processed/test",
        help="Test veri seti dizini"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="./results/validation",
        help="Ã‡Ä±ktÄ± dizini"
    )
    parser.add_argument(
        "--max-images",
        type=int,
        default=None,
        help="Her sÄ±nÄ±f iÃ§in maksimum gÃ¶rsel sayÄ±sÄ±"
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=50.0,
        help="SÄ±nÄ±flandÄ±rma eÅŸiÄŸi (0-100)"
    )

    args = parser.parse_args()

    # BaÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
    if not check_dependencies():
        sys.exit(1)

    try:
        # Ã‡Ä±ktÄ± dizinini oluÅŸtur
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. Veri setini yÃ¼kle
        logger.info("ğŸ”„ ADIM 1: Veri seti yÃ¼kleniyor...")
        test_dir = Path(args.data)
        dataset, info = load_test_dataset(test_dir, max_per_class=args.max_images)

        if not dataset:
            logger.error("âŒ Veri seti boÅŸ veya bulunamadÄ±")
            sys.exit(1)

        # 2. Ensemble motorunu baÅŸlat
        logger.info("ğŸ”„ ADIM 2: Ensemble motoru baÅŸlatÄ±lÄ±yor...")
        engine = initialize_ensemble()
        engine.threshold = args.threshold

        # 3. Analiz yap
        logger.info("ğŸ”„ ADIM 3: GÃ¶rseller analiz ediliyor...")
        y_true = []
        y_pred = []
        y_scores = []
        processing_times = []

        for filename, image, true_label in dataset:
            start = time.time()
            result = engine.analyze(image)
            proc_time = time.time() - start

            y_true.append(true_label)
            y_scores.append(result.final_score)
            # Score >= threshold â†’ FAKE (1), otherwise REAL (0)
            y_pred.append(1 if result.final_score >= args.threshold else 0)
            processing_times.append(proc_time)

            if len(y_true) % 10 == 0:
                logger.info(f"  Ä°lerleme: {len(y_true)}/{len(dataset)}")

        # 4. Metrikleri hesapla
        logger.info("ğŸ”„ ADIM 4: Metrikler hesaplanÄ±yor...")
        metrics = compute_metrics(y_true, y_pred, y_scores)

        # Ortalama iÅŸlem sÃ¼resi
        metrics['avg_processing_time'] = sum(processing_times) / len(processing_times)
        metrics['total_images'] = len(dataset)
        metrics['threshold'] = args.threshold

        # 5. GÃ¶rselleÅŸtirmeler
        logger.info("ğŸ”„ ADIM 5: GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")

        # Confusion Matrix
        cm = metrics['confusion_matrix']
        import numpy as np
        plot_confusion_matrix(np.array(cm), output_dir / "confusion_matrix.png")

        # ROC Curve
        roc_data = metrics['roc_curve']
        plot_roc_curve(
            roc_data['fpr'],
            roc_data['tpr'],
            metrics['roc_auc'],
            output_dir / "roc_curve.png"
        )

        # Skor daÄŸÄ±lÄ±mÄ±
        y_scores_real = [y_scores[i] for i in range(len(y_true)) if y_true[i] == 0]
        y_scores_fake = [y_scores[i] for i in range(len(y_true)) if y_true[i] == 1]
        plot_score_distribution(y_scores_real, y_scores_fake, output_dir / "score_distribution.png")

        # 6. False Positive Analizi
        logger.info("ğŸ”„ ADIM 6: False positive analizi yapÄ±lÄ±yor...")
        analyze_false_positives(dataset, y_true, y_pred, y_scores, output_dir)

        # 7. RaporlarÄ± kaydet
        logger.info("ğŸ”„ ADIM 7: Raporlar kaydediliyor...")
        generate_report(metrics, output_dir)
        save_metrics_json(metrics, output_dir / "metrics.json")

        # 8. Ã–zet
        logger.info("\n" + "="*50)
        logger.info("ğŸ‰ DoÄŸrulama tamamlandÄ±!")
        logger.info("="*50)
        logger.info(f"âœ… Accuracy: %{metrics['accuracy']*100:.2f}")
        logger.info(f"âœ… Precision: {metrics['precision']:.4f}")
        logger.info(f"âœ… Recall: {metrics['recall']:.4f}")
        logger.info(f"âœ… F1 Score: {metrics['f1_score']:.4f}")
        logger.info(f"âœ… ROC AUC: {metrics['roc_auc']:.4f}")
        logger.info(f"âœ… FPR: %{metrics['false_positive_rate']*100:.2f}")
        logger.info(f"âœ… Ortalama iÅŸlem sÃ¼resi: {metrics['avg_processing_time']:.3f}s")
        logger.info("="*50)
        logger.info(f"ğŸ“ SonuÃ§lar: {output_dir}")

    except Exception as e:
        logger.error(f"âŒ Hata: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
