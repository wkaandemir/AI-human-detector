#!/usr/bin/env python3
"""
AI Human Detector - Veri Seti Ä°ndirme Scripti

Bu script, HuggingFace'ten gerÃ§ek ve AI Ã¼retilmiÅŸ yÃ¼z verisetlerini indirir.
KullanÄ±m:
    python scripts/download_dataset.py --dataset all --output ./data
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Optional, Tuple
import logging

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_dependencies() -> bool:
    """
    Gerekli kÃ¼tÃ¼phanelerin kurulu olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    """
    try:
        import datasets
        import PIL
        import tqdm
        logger.info("âœ… TÃ¼m baÄŸÄ±mlÄ±lÄ±klar kurulu")
        return True
    except ImportError as e:
        logger.error(f"âŒ Eksik baÄŸÄ±mlÄ±lÄ±k: {e}")
        logger.info("Kurulum iÃ§in: pip install datasets pillow tqdm")
        return False


def download_celeba_hq(
    output_dir: Path,
    num_samples: Optional[int] = None,
    split: str = "train"
) -> Path:
    """
    CelebA-HQ verisetini HuggingFace'ten indirir.

    Args:
        output_dir: Ã‡Ä±ktÄ± dizini
        num_samples: Ä°ndirilecek Ã¶rnek sayÄ±sÄ± (None = tÃ¼mÃ¼)
        split: Veri seti bÃ¶lmesi

    Returns:
        Ä°ndirilen verisetinin dizini
    """
    try:
        from datasets import load_dataset
        from tqdm import tqdm

        logger.info("ğŸ“¥ CelebA-HQ veriseti indiriliyor...")

        # Verisetini yÃ¼kle (streaming modu)
        dataset = load_dataset(
            "mattymchen/celeba-hq",
            split=split,
            streaming=True
        )

        # Ã‡Ä±ktÄ± dizinini oluÅŸtur
        celeba_dir = output_dir / "real" / "celeba_hq"
        celeba_dir.mkdir(parents=True, exist_ok=True)

        # GÃ¶rselleri indir ve kaydet
        count = 0
        for example in tqdm(dataset, desc="CelebA-HQ indiriliyor"):
            if num_samples and count >= num_samples:
                break

            # GÃ¶rseli kaydet
            image = example["image"]
            image_path = celeba_dir / f"celeba_{count:05d}.png"
            image.save(image_path)
            count += 1

        logger.info(f"âœ… CelebA-HQ: {count} gÃ¶rsel indirildi -> {celeba_dir}")
        return celeba_dir

    except Exception as e:
        logger.error(f"âŒ CelebA-HQ indirme hatasÄ±: {e}")
        raise


def download_coco_ai(
    output_dir: Path,
    num_samples: Optional[int] = None,
    split: str = "train"
) -> Path:
    """
    COCO_AI verisetini (AI Ã¼retilmiÅŸ gÃ¶rseller) HuggingFace'ten indirir.

    Args:
        output_dir: Ã‡Ä±ktÄ± dizini
        num_samples: Ä°ndirilecek Ã¶rnek sayÄ±sÄ± (None = tÃ¼mÃ¼)
        split: Veri seti bÃ¶lmesi

    Returns:
        Ä°ndirilen verisetinin dizini
    """
    try:
        from datasets import load_dataset
        from tqdm import tqdm

        logger.info("ğŸ“¥ COCO_AI veriseti indiriliyor...")

        # Verisetini yÃ¼kle
        dataset = load_dataset(
            "NasrinImp/COCO_AI",
            split=split,
            streaming=True
        )

        # Ã‡Ä±ktÄ± dizinini oluÅŸtur
        coco_dir = output_dir / "fake" / "coco_ai"
        coco_dir.mkdir(parents=True, exist_ok=True)

        # GÃ¶rselleri indir ve kaydet
        count = 0
        for example in tqdm(dataset, desc="COCO_AI indiriliyor"):
            if num_samples and count >= num_samples:
                break

            # GÃ¶rseli kaydet (genellikle 'image' anahtarÄ±)
            if "image" in example:
                image = example["image"]
            elif "jpg" in example:
                image = example["jpg"]
            else:
                logger.warning(f"âš ï¸ Beklenmeyen veri formatÄ±: {example.keys()}")
                continue

            image_path = coco_dir / f"coco_ai_{count:05d}.png"
            image.save(image_path)
            count += 1

        logger.info(f"âœ… COCO_AI: {count} gÃ¶rsel indirildi -> {coco_dir}")
        return coco_dir

    except Exception as e:
        logger.error(f"âŒ COCO_AI indirme hatasÄ±: {e}")
        raise


def download_dataset(
    dataset_name: str,
    output_dir: Path,
    num_samples: Optional[int] = None
) -> None:
    """
    Belirtilen verisetini indirir.

    Args:
        dataset_name: Veriseti adÄ± ('celeba_hq', 'coco_ai', veya 'all')
        output_dir: Ã‡Ä±ktÄ± dizini
        num_samples: Ä°ndirilecek Ã¶rnek sayÄ±sÄ±
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    if dataset_name in ["celeba_hq", "all"]:
        download_celeba_hq(output_dir, num_samples)

    if dataset_name in ["coco_ai", "all"]:
        download_coco_ai(output_dir, num_samples)


def create_sample_dataset(
    real_dir: Path,
    fake_dir: Path,
    output_dir: Path,
    num_real: int = 50,
    num_fake: int = 50
) -> Tuple[Path, Path]:
    """
    Manuel test iÃ§in kÃ¼Ã§Ã¼k bir Ã¶rnek veriseti oluÅŸturur.

    Args:
        real_dir: GerÃ§ek gÃ¶rseller dizini
        fake_dir: Sahte gÃ¶rseller dizini
        output_dir: Ã‡Ä±ktÄ± dizini
        num_real: Ã–rnek gerÃ§ek gÃ¶rsel sayÄ±sÄ±
        num_fake: Ã–rnek sahte gÃ¶rsel sayÄ±sÄ±

    Returns:
        (real_sample_dir, fake_sample_dir)
    """
    import shutil
    import random

    logger.info(f"ğŸ“¦ Ã–rnek veriseti oluÅŸturuluyor: {num_real} gerÃ§ek, {num_fake} sahte")

    # Dizinleri oluÅŸtur
    sample_real = output_dir / "sample_real"
    sample_fake = output_dir / "sample_fake"
    sample_real.mkdir(parents=True, exist_ok=True)
    sample_fake.mkdir(parents=True, exist_ok=True)

    # GerÃ§ek gÃ¶rsellerden Ã¶rnek al
    real_images = list(real_dir.glob("*.png")) + list(real_dir.glob("*.jpg"))
    if len(real_images) >= num_real:
        selected_real = random.sample(real_images, num_real)
        for img in selected_real:
            shutil.copy2(img, sample_real / img.name)
        logger.info(f"âœ… {num_real} gerÃ§ek gÃ¶rsel kopyalandÄ±")
    else:
        logger.warning(f"âš ï¸ Yeterli gerÃ§ek gÃ¶rsel yok: {len(real_images)} < {num_real}")

    # Sahte gÃ¶rsellerden Ã¶rnek al
    fake_images = list(fake_dir.glob("*.png")) + list(fake_dir.glob("*.jpg"))
    if len(fake_images) >= num_fake:
        selected_fake = random.sample(fake_images, num_fake)
        for img in selected_fake:
            shutil.copy2(img, sample_fake / img.name)
        logger.info(f"âœ… {num_fake} sahte gÃ¶rsel kopyalandÄ±")
    else:
        logger.warning(f"âš ï¸ Yeterli sahte gÃ¶rsel yok: {len(fake_images)} < {num_fake}")

    return sample_real, sample_fake


def main():
    parser = argparse.ArgumentParser(
        description="AI Human Detector - Veri Seti Ä°ndirme Scripti"
    )
    parser.add_argument(
        "--dataset",
        type=str,
        choices=["celeba_hq", "coco_ai", "all"],
        default="all",
        help="Ä°ndirilecek veriseti"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="./data/datasets",
        help="Ã‡Ä±ktÄ± dizini"
    )
    parser.add_argument(
        "--num-samples",
        type=int,
        default=None,
        help="Her verisetinden indirilecek maksimum Ã¶rnek sayÄ±sÄ±"
    )
    parser.add_argument(
        "--create-sample",
        action="store_true",
        help="Manuel test iÃ§in 50+50 Ã¶rnek veriseti oluÅŸtur"
    )

    args = parser.parse_args()

    # BaÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
    if not check_dependencies():
        sys.exit(1)

    try:
        # Verisetini indir
        download_dataset(
            dataset_name=args.dataset,
            output_dir=Path(args.output),
            num_samples=args.num_samples
        )

        # Ã–rnek veriseti oluÅŸtur (isteÄŸe baÄŸlÄ±)
        if args.create_sample:
            real_dir = Path(args.output) / "real" / "celeba_hq"
            fake_dir = Path(args.output) / "fake" / "coco_ai"

            if real_dir.exists() and fake_dir.exists():
                sample_output = Path(args.output) / "sample"
                create_sample_dataset(
                    real_dir=real_dir,
                    fake_dir=fake_dir,
                    output_dir=sample_output,
                    num_real=50,
                    num_fake=50
                )
            else:
                logger.warning("âš ï¸ Ã–rnek veriseti oluÅŸturulamadÄ±: kaynak dizinler yok")

        logger.info("ğŸ‰ Ä°ndirme tamamlandÄ±!")

    except Exception as e:
        logger.error(f"âŒ Hata: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
